# =====================================================
# LiteLLM Configuration - CloudFreedom AI Router
# WORKING CONFIG with REAL MODELS (October 2025)
# =====================================================

model_list:
  # ===================================================
  # GOOGLE GEMINI - Direct API (No Vertex)
  # ===================================================
  
  - model_name: gemini-1.5-pro
    litellm_params:
      model: gemini/gemini-1.5-pro
      api_key: ${GOOGLE_API_KEY}
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
      max_tokens: 1048576
      input_cost_per_token: 0.00000125
      output_cost_per_token: 0.000005
  
  - model_name: gemini-1.5-flash
    litellm_params:
      model: gemini/gemini-1.5-flash
      api_key: ${GOOGLE_API_KEY}
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
      max_tokens: 1048576
      input_cost_per_token: 0.000000075
      output_cost_per_token: 0.0000003

  # ===================================================
  # AZURE OPENAI GPT-4o - Germany West Central
  # ===================================================
  
  - model_name: gpt-4o
    litellm_params:
      model: azure/gpt-4o
      api_base: ${AZURE_OPENAI_ENDPOINT}
      api_key: ${AZURE_OPENAI_API_KEY}
      api_version: ${AZURE_OPENAI_API_VERSION:-2024-08-01-preview}
      azure_deployment: ${AZURE_OPENAI_DEPLOYMENT_NAME:-gpt-4o}
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
      max_tokens: 16384
      input_cost_per_token: 0.0000025
      output_cost_per_token: 0.00001

  # ===================================================
  # AWS BEDROCK CLAUDE - EU Frankfurt
  # ===================================================
  
  - model_name: claude-3.5-sonnet
    litellm_params:
      model: bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0
      aws_region_name: ${AWS_REGION_NAME:-eu-central-1}
      aws_bedrock_runtime_endpoint: https://bedrock-runtime.${AWS_BEDROCK_RUNTIME_REGION:-eu-central-1}.amazonaws.com
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
      max_tokens: 8192
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000015
  
  - model_name: claude-3-haiku
    litellm_params:
      model: bedrock/anthropic.claude-3-haiku-20240307-v1:0
      aws_region_name: ${AWS_REGION_NAME:-eu-central-1}
    model_info:
      mode: chat
      supports_function_calling: true
      max_tokens: 4096
      input_cost_per_token: 0.00000025
      output_cost_per_token: 0.00000125

# =====================================================
# General Settings
# =====================================================

general_settings:
  master_key: ${LITELLM_MASTER_KEY}
  database_url: ${DATABASE_URL}
  
  # Logging
  success_callback: []
  failure_callback: []
  
  # Rate Limiting & Caching
  redis_host: redis
  redis_port: 6379
  redis_password: ${REDIS_PASSWORD}
  
  # Budget Management
  max_budget: 1000
  budget_duration: "30d"
  
  # Fallbacks
  fallbacks:
    - gemini-1.5-flash: ["gemini-1.5-pro", "gpt-4o"]
    - gemini-1.5-pro: ["gpt-4o", "claude-3.5-sonnet"]
    - gpt-4o: ["claude-3.5-sonnet", "gemini-1.5-pro"]
    - claude-3.5-sonnet: ["gpt-4o", "gemini-1.5-pro"]
    - claude-3-haiku: ["gemini-1.5-flash", "gpt-4o"]
  
  # Load Balancing
  router_settings:
    routing_strategy: "cost-based-routing"
    model_group_alias:
      fast: ["gemini-1.5-flash", "claude-3-haiku"]
      balanced: ["gemini-1.5-pro", "claude-3.5-sonnet", "gpt-4o"]
      premium: ["claude-3.5-sonnet", "gpt-4o", "gemini-1.5-pro"]
      long-context: ["gemini-1.5-pro", "gemini-1.5-flash"]

# =====================================================
# Callbacks & Integrations
# =====================================================

litellm_settings:
  # CloudFreedom Billing Integration
  success_callback: []
  
  # Drop params not supported by provider
  drop_params: true
  
  # Set max retries
  num_retries: 3
  request_timeout: 600
  
  # Enable streaming
  stream: true
  
  # Set RPM/TPM limits
  rpm: 500
  tpm: 100000


